{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Smote Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy svm: 0.92063\n",
      "Test accuracy svm: 0.87038\n",
      "\n",
      "Train accuracy forest : 0.99988\n",
      "Test accuracy forest : 0.91227\n"
     ]
    }
   ],
   "source": [
    "Training_data = pd.read_csv('train.csv', index_col=0)\n",
    "df = Training_data.copy()\n",
    "df = df.dropna()\n",
    "df = df[df.Landsize != 0.0]\n",
    "df = df.drop(['Bedrooms'], axis =1)\n",
    "df = pd.get_dummies(df,columns=['Type','Method','Regionname'])\n",
    "#----------------------------------------------------\n",
    "# Fixing the Test Data\n",
    "Test_data = pd.read_csv('test.csv', index_col=0)\n",
    "Test_data = Test_data.drop(['Bedrooms'], axis =1)\n",
    "Test_data = pd.get_dummies(Test_data,columns=['Type','Method','Regionname'])\n",
    "#-----------------------------------------------------\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=7)\n",
    "\n",
    "# Fit the model to generate the data.\n",
    "oversampled_trainX, oversampled_trainY = sm.fit_resample(df.drop('Price class', axis=1), df['Price class'])\n",
    "oversampled_train = pd.concat([pd.DataFrame(oversampled_trainY), pd.DataFrame(oversampled_trainX)], axis=1)\n",
    "df = oversampled_train\n",
    "\n",
    "#_---------------------------------------------------\n",
    "\n",
    "X = df.iloc[:,1:].copy()\n",
    "y = df.iloc[:,0].copy()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=100, stratify= y)\n",
    "#----------------------------------------------------\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                        n_estimators=100, \n",
    "                                        random_state= 100,\n",
    "                                        n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "FTrain = forest.score(X_train, y_train)\n",
    "FTest  = forest.score(X_test, y_test)\n",
    "\n",
    "#------------------------------------------------------\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=20, random_state=100)\n",
    "svm.fit(X_train_sc, y_train)\n",
    "\n",
    "print('Train accuracy svm: {0:.5f}'.format(svm.score(X_train_sc, y_train)))\n",
    "print('Test accuracy svm: {0:.5f}'.format(svm.score(X_test_sc, y_test)))\n",
    "print()\n",
    "\n",
    "print('Train accuracy forest : {0:.5f}'.format(forest.score(X_train, y_train)))\n",
    "print('Test accuracy forest : {0:.5f}'.format(forest.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_xtrain = X\n",
    "forest_ytrain = y\n",
    "forest_test = Test_data\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=100,\n",
    "                                random_state= 100,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(forest_xtrain, forest_ytrain)\n",
    "\n",
    "forest_target_predictions = forest.predict(forest_test)\n",
    "output = pd.DataFrame({'index': forest_test.index,'Price class': forest_target_predictions})\n",
    "output.to_csv('CA4_submission_forest',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_xtrain = X\n",
    "svc_ytrain = y\n",
    "svc_test = Test_data\n",
    "\n",
    "Train_sc = sc.transform(X)\n",
    "Test_sc = sc.transform(svc_test)\n",
    "\n",
    "svm.fit(Train_sc,y)\n",
    "\n",
    "svc_target_predictions = svm.predict(Test_sc)\n",
    "\n",
    "output = pd.DataFrame({'index': svc_test.index,'Price class': svc_target_predictions})\n",
    "output.to_csv('CA4_submission_svc',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tomek links undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9761, 26)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_data = pd.read_csv('train.csv', index_col=0)\n",
    "df = Training_data.copy()\n",
    "df = df.drop(['YearBuilt', 'Bedrooms'], axis =1)\n",
    "df = df.dropna()\n",
    "df = df[df.Landsize != 0.0]\n",
    "df = pd.get_dummies(df,columns=['Type','Method','Regionname'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks()\n",
    "\n",
    "undersample_trainX, undersample_trainY = tl.fit_resample(df.drop('Price class', axis=1), df['Price class'])\n",
    "undersample_train = pd.concat([pd.DataFrame(undersample_trainY), pd.DataFrame(undersample_trainX)], axis=1)\n",
    "df = undersample_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean encoding\n",
    "mean_encoding_weather = df.groupby(['weather_situation'])['temperature'].mean().to_dict()\n",
    "mean_encoding_season = df.groupby(['season'])['temperature'].mean().to_dict()\n",
    "\n",
    "df['mean_weather'] = df['weather_situation'].map(mean_encoding_weather)\n",
    "df['mean_season'] = df['season'].map(mean_encoding_season)\n",
    "\n",
    "## freq encoding\n",
    "freq_encoding_hour = df['hour'].value_counts()\n",
    "freq_encoding_month = df['month'].value_counts()\n",
    "freq_encoding_weekday = df['weekday'].value_counts()\n",
    "\n",
    "df['freq_hour'] = df['hour'].map(freq_encoding_hour)\n",
    "df['freq_month'] = df['month'].map(freq_encoding_month)\n",
    "df['freq_weekday'] = df['weekday'].map(freq_encoding_weekday)\n",
    "\n",
    "#scaling \n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[['freq_hour','freq_month','freq_weekday']] = min_max_scaler.fit_transform(df[['freq_hour','freq_month','freq_weekday']])\n",
    "\n",
    "# Dropping the rest columns\n",
    "df = df.drop(['hour','month','weekday','weather_situation','season'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoding_hour = dft.groupby(['hour'])['rental_bikes_count'].mean().to_dict()\n",
    "mean_encoding_month = dft.groupby(['month'])['rental_bikes_count'].mean().to_dict()\n",
    "mean_encoding_weekday = dft.groupby(['weekday'])['rental_bikes_count'].mean().to_dict()\n",
    "mean_encoding_weather = dft.groupby(['weather_situation'])['rental_bikes_count'].mean().to_dict()\n",
    "mean_encoding_season = dft.groupby(['season'])['rental_bikes_count'].mean().to_dict()\n",
    "\n",
    "dft['mean_hour'] = dft['hour'].map(mean_encoding_hour)\n",
    "dft['mean_month'] = dft['month'].map(mean_encoding_month)\n",
    "dft['mean_weekday'] = dft['weekday'].map(mean_encoding_weekday)\n",
    "dft['mean_weather'] = dft['weather_situation'].map(mean_encoding_weather)\n",
    "dft['mean_season'] = dft['season'].map(mean_encoding_season)\n",
    "\n",
    "#scaling \n",
    "min_max_scaler = MinMaxScaler()\n",
    "dft[['mean_hour','mean_month','mean_weekday','mean_weather','mean_season']] = min_max_scaler.fit_transform(dft[['mean_hour','mean_month','mean_weekday','mean_weather','mean_season']])\n",
    "\n",
    "# Dropping the rest columns\n",
    "dft = dft.drop(['hour','month','weekday','weather_situation','season'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "8481    1\n",
       "8482    2\n",
       "8483    0\n",
       "8484    0\n",
       "8485    0\n",
       "Name: Price class, Length: 8486, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = df.drop('Price class', axis = 1).copy(), df['Price class'].copy()\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=100, stratify= y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy forest: 0.92063\n",
      "Test accuracy forest: 0.87038\n",
      "Train accuracy SVM : 0.99988\n",
      "Test accuracy SVM : 0.90833\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                        n_estimators=500, \n",
    "                                        random_state= 100,\n",
    "                                        n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "FTrain = forest.score(X_train, y_train)\n",
    "FTest  = forest.score(X_test, y_test)\n",
    "\n",
    "#------------------------------------------------------\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=20, random_state=100)\n",
    "svm.fit(X_train_sc, y_train)\n",
    "\n",
    "print('Train accuracy forest: {0:.5f}'.format(svm.score(X_train_sc, y_train)))\n",
    "print('Test accuracy forest: {0:.5f}'.format(svm.score(X_test_sc, y_test)))\n",
    "\n",
    "print('Train accuracy SVM : {0:.5f}'.format(forest.score(X_train, y_train)))\n",
    "print('Test accuracy SVM : {0:.5f}'.format(forest.score(X_test, y_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
